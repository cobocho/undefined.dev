---
title: '프론트엔드 개발자의 AWS SAA(Solution Architect Associate) 취득기 (with AI)'
description: '엄마, 난 커서 솔루션 아키텍트가 될래요'
date: '2025/05/07'
tags: ['AWS', 'SAA', 'Solution Architect Associate', 'OpenAI']
---

# 개요

이번에 **AWS SAA(Solution Architect Associate)-C03** 자격증을 취득했습니다.

별 계기가 있어서 취득했다기 보다는 이번에 홈서버를 구축하고 조금씩 쪼물딱거리면서 가지고 놀다가, 갑자기 이런 귀찮은 일들을 전부 딱딱 알아서 AWS나 Azure같은 CSP(Cloud Service Provider)들이 이런걸 어떻게 처리하나 좀 궁금해졌거든요. 기왕 공부도 할 겸 자격증도 취득해보려고 AWS SAA를 준비하게 되었습니다.
개인적으로는 AWS를 조금씩 써본 경험은 있지만 자세하게 다뤄보진 않았습니다. 본업이 프론트엔드다보니 사내에서 인프라를 직접 만지는 일은 가끔씩만 존재했었고 개인적으로 인프라가 필요할때도 사실 [Supabase](https://supabase.com/)나 [Vercel](https://vercel.com/)같은 적당한 `as a Service`들을 활용하면 충분했었거든요. 그게 마음도 더 편하구요.

근데 그래도 이번 기회에 AWS를 공부하면 나중에 언젠가는 도움이 될 것 같기도 했고, 가장 큰 이유는 홈 서버를 관리할때 어떻게 시스템을 구축하는게 좋을지에 대한 정보를 얻을 수 있을 것 같아서 취득하게 되었습니다.

그리고 마침 AWS 자격증 50% 할인 바우처가 풀린 것도 이유중 하나였어요.

## SAA 취득 이유

AWS의 권장 커리큘럼도 그렇고 AI한테 물어봤을때도 프론트엔드 개발자에게는 SAA보다는 **DVA(Developer Associate)** 를 추천하는 경우가 많았습니다. 그런데 찾아보니 DVA의 경우는 서버리스 서비스나 CI/CD 관련 개념들이 주요 출제범위였어요. 제 취득 목적에는 DVA보다는 SAA가 더 적합해보여서 SAA를 준비하게 되었습니다.

# 공부 방법

공부 기간은 대략 3주에서 4주 정도 공부했습니다. 평일에도 출퇴근길에 짬짬이 보거나 퇴근 후에도 좀 보고 주말에 남는 시간도 꽤 활용했습니다.

인터넷에서 찾아보니 주로 채택하는 방법이 [Udemy 강의](https://www.udemy.com/course/best-aws-certified-solutions-architect-associate/?couponCode=KEEPLEARNING), 책 구매, 그리고 덤프 풀이 이렇게 나뉘었습니다. 책의 경우는 C03 기준 서적이 없고 강의의 경우는 27시간이라는 시간의 압박으로 인해 다른 방법을 찾아보기로 했습니다.

## 출제 범위 분류하기

![](1.png)

우선 AI한테 AWS SAA의 출제 범위를 출제 빈도에 맞춰서 분류해달라고 했습니다. 그걸 체크박스 리스트로 만들어서 각 항목별로 유튜브에 공개된 강의나 발표 영상들을 찾아서 매핑했어요. 주로 [AWS 강의실](https://www.youtube.com/@AWSClassroom), [Amazon Web Services Korea](https://www.youtube.com/@AWSKorea) 채널을 주로 참고했어요.

## 덤프 데이터 만들기

위에서 분류한 영상들을 모두 시청하고 실습한 이후, SAA-C03 덤프를 풀기 시작했습니다.
취득 후기글을 읽어보니 실제 시험에서 일정 부분의 문제들은 덤프에서 출제된다고 하더라구요. 일종의 문제은행 형식의 시험처럼 보였습니다.

어떻게 하면 조금 더 효과적으로 덤프를 풀 수 있을까 고민했어요. 그래서 덤프를 좀 더 잘 기억할 수 있고록 문제를 풀고, 해설을 확인하고, 내 마음대로 분류할 수 있는 있는 간단한 웹 어플리케이션을 만들기로 했습니다.

만드는 순서는 다음과 같습니다.

1. 온라인에 풀려있는 덤프 목록을 구한다.
2. 덤프를 JSON 형식으로 변환한다.
3. OpenAI API를 통해 해당 문제의 해설과, 문제 내 서비스들의 설명을 추가한다.
4. 보강된 덤프 목록을 바탕으로 문제를 풀 수 있는 웹 어플리케이션을 만든다.

우선 첫번째로 인터넛에 올라온 덤프 목록을 구했습니다. 대략 700문제 정도 담겨있는 PDF 파일을 TXT로 추출한 후 JSON 형식으로 변환했어요. 그리고 [OpenAI API](https://platform.openai.com/docs/api-reference/chat/create)를 통해 해당 문제의 해설과 지문 내 서비스들의 설명을 추가했습니다.

![](2.png)

OpenAI API에서 차단하는걸 방지하기위해 한번에 50개씩 병렬처리해서 API를 호출했는데, 전체 싸이클을 돌릴때마다 `4o-mini` 모델 기준으로 0.3달러 정도 들었던 것 같아요. API 요청 이후에는 이런 데이터가 생성되었습니다.

```json
{
  "no": 1,
  "question": "Q1  회사는 여러 대륙에 걸쳐 도시의 온도, 습도 및 대기압에 대한 데이터를 수집합니다.  회사가 매일 각 사이트에서 수집하는 데이터의 평균 볼륨은 500GB 입니다. 각 사이트에는  고속 인터넷 연결이 있습니다.  이 회사는 이러한 모든 글로벌 사이트의 데이터를 단일 Amazon S3 버킷에 최대한 빨리  집계하려고 합니다. 솔루션은 운영 복잡성을 최소화해야 합니다.  어떤 솔루션이 이러한 요구 사항을 충족합니까? ",
  "answers": {
    "a": "대상 S3 버킷에서 S3 Transfer Acceleration 을 켭니다. 멀티파트 업로드를 사용하여\n 사이트 데이터를 대상 S3 버킷에 직접 업로드합니다.\n",
    "b": "각 사이트의 데이터를 가장 가까운 리전의 S3 버킷에 업로드합니다. S3 교차 리전\n 복제를 사용하여 대상 S3 버킷에 객체를 복사합니다. 그런 다음 원본 S3 버킷에서\n 데이터를 제거합니다.\n",
    "c": "AWS Snowball Edge Storage Optimized 디바이스 작업을 매일 예약하여 각 사이트에서\n 가장 가까운 리전으로 데이터를 전송합니다. S3 교차 리전 복제를 사용하여 대상 S3 버킷에\n 객체를 복사합니다.\n",
    "d": "각 사이트의 데이터를 가장 가까운 리전의 Amazon EC2 인스턴스로 업로드합니다.\n Amazon Elastic Block Store(Amazon EBS) 볼륨에 데이터를 저장합니다. 정기적으로 EBS\n 스냅샷을 만들어 대상 S3 버킷이 포함된 리전에 복사합니다. 해당 리전에서 EBS 볼륨을\n 복원합니다.\n\n\n\n\n"
  },
  "answer": ["a"],
  "explanation": [
    "・ 여러 글로벌 사이트의 데이터를 단일 Amazon S3 버킷에 최대한 빨리 집계하는 동시에 운영 복잡성을 최소화하려면 가장 적합한 솔루션은 옵션 A: 대상 S3 버킷에서 S3 전송 가속화를 설정하고 멀티파트 업로드를 사용하여 사이트 데이터를 대상 S3 버킷에 직접 업로드하는 것입니다. 요약하면 옵션 A 는 여러 글로벌 사이트의 데이터를 단일 Amazon S3 버킷으로 신속하게 집계하는 가장 효율적이고 운영상 간단한 솔루션을 제공합니다. S3 Transfer Acceleration 및 멀티파트 업로드를 활용하여 회사는 복잡성을 최소화하면서 빠른 데이터 수집을 달성할 수 있습니다."
  ],
  "ai": {
    "explanation": "정답은 A입니다. S3 Transfer Acceleration을 사용하면 데이터가 Amazon S3로 더 빠르게 전송될 수 있습니다. 멀티파트 업로드를 통해 대용량 데이터를 효율적으로 업로드할 수 있으며, 이는 운영 복잡성을 최소화하는 데 도움이 됩니다. B는 S3 교차 리전 복제를 사용하여 데이터를 복사하는 과정이 추가되어 복잡성이 증가합니다. C는 AWS Snowball을 사용하여 데이터를 전송하는 방법으로, 물리적 장비를 사용해야 하므로 운영 복잡성이 증가합니다. D는 EC2 인스턴스를 사용하여 데이터를 업로드하고 EBS 스냅샷을 생성하는 방법으로, 이 또한 복잡성을 증가시킵니다.",
    "answer": ["A"],
    "causes": {
      "A": "S3 Transfer Acceleration을 사용하면 데이터 전송 속도가 빨라지고, 멀티파트 업로드를 통해 대용량 데이터를 효율적으로 처리할 수 있어 운영 복잡성을 최소화할 수 있습니다.",
      "B": "S3 교차 리전 복제를 사용하여 데이터를 복사하는 과정이 추가되어 복잡성이 증가합니다.",
      "C": "AWS Snowball을 사용하여 데이터를 전송하는 방법으로, 물리적 장비를 사용해야 하므로 운영 복잡성이 증가합니다.",
      "D": "EC2 인스턴스를 사용하여 데이터를 업로드하고 EBS 스냅샷을 생성하는 방법으로, 이 또한 복잡성을 증가시킵니다."
    },
    "services": {
      "S3 Transfer Acceleration": "데이터를 Amazon S3로 더 빠르게 전송할 수 있도록 지원하는 기능.",
      "S3": "대용량 데이터를 저장하고 관리할 수 있는 객체 스토리지 서비스.",
      "S3 교차 리전 복제": "한 리전의 S3 버킷에서 다른 리전의 S3 버킷으로 객체를 복사하는 기능.",
      "AWS Snowball Edge Storage Optimized": "대량의 데이터를 물리적으로 전송하기 위한 장비.",
      "Amazon EC2": "가상 서버를 제공하여 애플리케이션을 실행할 수 있는 서비스.",
      "Amazon Elastic Block Store (EBS)": "EC2 인스턴스에 연결할 수 있는 블록 스토리지 서비스."
    }
  },
  "dumpurl": "https://www.examtopics.com/discussions/amazon/view/84973-exam-aws-certified-solutions-architect-associate-saa-c03/"
}
```

그리고 보강된 덤프 목록을 바탕으로 문제를 풀 수 있는 웹 어플리케이션을 만들었습니다.

![](3.png)

![](4.png)

![](5.png)

![](6.png)

해당 어플리케이션을 출퇴근시간이랑 남는 시간마다 반복해서 돌렸습니다. 랜덤으로 문제를 뽑아서 풀고 해설을 바로바로 확인할 수 있으니 기억에 좀 더 잘 남았던 것 같아요.

# 시험 당일

AWS 자격증 시험의 경우 총 **130분** 의 시간이 주어지며 **65개** 의 문제를 풀어야 합니다.
온라인과 오프라인, 2가지의 방식으로 시험을 볼 수 있어요. 오프라인의 경우는 AWS에서 지정한 시험장에 직접 가서 시험을 풀고 오프라인의 경우는 웹캠을 킨 상태로 감독관의 지시에 따라 시험을 응시하는 방식입니다. 온라인과 오프라인 모두 준비물로 **신분증**, **영어 신분 증명(여권, 신용카드)** 이 필요합니다. 여권이나 신용카드 하나만으로는 인증 과정에서 이슈가 존재했다는 후기들이 있어서 저는 일단 전부 가져갔어요.

다른 후기에서 온라인 시험에서 의도치 않은 부정행위로 인해 탈락 처리 케이스가 있었다고 하는걸 보고 오프라인에서 시험을 보기로 결정했습니다. 어차피 당일 오후에 SIPE 오리엔테이션 일정이 있기도해서 선정릉역에 위치한 **SRTC** 에서 시험을 보기로 했습니다.

![SRTC 시험장 (출처: SRTC 홈페이지)](7.png)

SRTC 시험장 기준으로 오프라인 시험의 경우는 시험장에 방문하여 약간의 양식과 동의서를 작성한 이후 개인 물품을 보관하고 지정된 좌석에서 시험을 보는 방식이었어요. 필기가 가능한 보드와 마커도 제공합니다.

전반적으로 시험 환경 자체는 쾌적했습니다.

# 시험 후기

![](8.png)

저는 827점의 점수로 합격했습니다. 10시에 시험을 응시하여 대략 당일 오후 8시 즈음에 결과 발표 메일이 왔어요.

전반적으로 대략 **덤프의 30%** 정도가 본시험에서 출제된 느낌이었습니다. 다만 덤프에서 보지 못했던 문제라도, 문제의 형식이나 개념 자체는 어느정도 비슷한 결로 출제되기에 덤프를 많이 풀어보는게 확실히 도움이 되었습니다.
문제들이 어느정도 일관된 패턴 같은게 존재하다보니 그런 것도 있는것 같습니다. 예를 들어 짧은 소요 시간의 서비스의 경우는 AWS Lambda, 순서 보장 메시지의 경우에는 AWS SQS FIFO 등, 답안의 모든 서비스를 알지 못해도 지문을 보고 유추해서 정답을 찾을 수 있는 경우가 많았어요.

조금 솔직하게 말하자면 **"AWS SAA를 취득한다고해서 AWS를 잘한다"** 라는건 아닌 것 같습니다. 아무래도 CKA(Certified Kubernetes Administrator) 같은 시험처럼 핸즈 온 방식이 아닌 문제 은행 방식이다보니, AWS 자체의 개념보다는 덤프에 의존한다라는 느낌을 지울수가 없었어요. 그러다보니 제 공부방식이 마냥 좋은 방법은 또 아니었던것 같다는 생각도 들었습니다.

그래도 취득 이후로 AWS에 대한 지식은 확실히 많이 늘어났다는 체감은 들었습니다. EC2나 RDS, Lambda, S3 같은 익숙한 서비스들의 세부적인 요소부터, AWS SQS, Cognito 같은 생소한 서비스들도 알아 볼 수 있었거든요. 왜 AWS가 아마존의 캐시 카우인지 체감할 수 있었습니다. 추후에 AWS를 구축할 경우, 꽤나 도움이 될 수 있을거라 생각해요.

AWS 자격증은 한 번 취득시 이후 시험료가 50% 감면되니 어쩌면 나중에 Professional 자격증을 공부하는 날이 올 수도 있겠네요.
